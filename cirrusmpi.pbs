# This is a simple template script to run batch jobs on Cirrus at EPCC
#
# You only have to change two things to run an MPI program with it:
#
# 1) Make a copy of the script with the same name as your MPI executable,
#    eg if the executable is 'myjob' then type: cp cirrusmpi.pbs myjob.pbs
#
# 2) Set the variable "NPROC" appropriately (and "select" if NPROC > 36),
#    and your job will run using NPROC MPI processes.
#
# To run: qsub myjob.pbs
# For supervised practical sessions there may be a queue reserved for you.
#
# All screen output (stdout and stderr) will appear in a file called
# myjob.pbs.oXXXXX, where XXXXX is the job number assigned at submit time.
#
# David Henty, EPCC, 18/09/2016
#

#PBS -A d154
#PBS -j oe
#PBS -l walltime=00:01:00
#PBS -l place=excl
#PBS -l select=72

#----------------------------------------------------------------------#
# You should only have to change the following parameter NPROC, unless #
# running on more than 36 processes when "select=72" must be increased #
# The variable "select" should be set to 72 times the number of nodes  #
# Each node has 36 physical cores so if NPROC=144 then use select=288  #
#----------------------------------------------------------------------#

NPROC=4

#------------------------------------------------------------------------#
# You should not have to edit below here for simple MPI jobs             #
# This assumes you are using the SGI MPI toolkit and the Intel compilers #
#------------------------------------------------------------------------#

module load mpt
module load intel-compilers-17

cd $PBS_O_WORKDIR

MPIPROG=`basename $PBS_JOBNAME .pbs`
MPISIZE=$NPROC

# Spread the processes as evenly as possible across the nodes

CPN=36                                     # Cores Per Node (physical)
NCORE=$(( $(wc -l < $PBS_NODEFILE) / 2 ))  # cores reserved (physical)
NNODE=$(( NCORE / CPN ))                   # nodes reserved
PPN=$(( MPISIZE / NNODE ))                 # Processes Per Node

echo '--------------------------------------------------------------------------------'

echo 'Running MPI program' $MPIPROG 'on' $MPISIZE 'processes'
echo 'Started at' `date`
echo '--------------------------------------------------------------------------------'

# Ensure we place a maximum of 36 processes per node to avoid hyperthreads

(time mpiexec_mpt -n $MPISIZE -ppn $PPN ./$MPIPROG) 2>&1

echo '--------------------------------------------------------------------------------'
echo 'Finished at' `date`
